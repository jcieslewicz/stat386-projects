---
layout: post
title:  "Spoti-spy: EDA on Spotify Audio Track Data"
date:   2022-11-17
author: Joseph Cieslewicz
description: I use the principles of EDA to explore my personal spotify library.
image: /assets/images/Spotify_Developers_Logo.png
---

## Introduction

In my last post, I showed how to pull data from the Spotify Open API using the Spotipy wrapper. Now, I want to dig into that data to see what I can learn about my music library. This Exploratory Data Analysis (EDA) will serve not only to answer exploratory questions, but also to discover and prepare for other possible analyses (regressions, ML algorithms, etc.). This post will be structured as question, process, answer. You will likely have other questions depending on the nature of your dataset, but the processes here can be a helpful pattern.

## Question 1: What’s in my dataset?

After reading in a dataset, it’s helpful to visualize the first few rows. I do this with .head(), shown below:

![Head Table](https://github.com/jcieslewicz/stat386-projects/raw/main/assets/images/Head.JPG)

For a refresher on what these columns mean, see the Spotify API docs here. In my head, I notice the first column has an unusual name. It’s a leftover index, so I could drop it, but it will be useful later to us to have this numeric column, so instead I’ll rename it:

`saved_tracks.rename({'Unnamed: 0': 'recency'}, axis='columns', inplace = True)`

## Question 2: Is my dataset clean?

We cleaned this dataset as part of my last blog post, but when you’re starting an analysis you can never be sure. To make sure all the values of my features fall within reasonable ranges, I can call .describe() on a dataframe. I compare this against the variable descriptions on the API docs, and everything makes sense. This descriptive dataframe also contains a lot of useful summary statistics, but these will be easier to interpret visually a little later. I’ll also check for NA values and column types with .info(). 

![Info Table](https://github.com/jcieslewicz/stat386-projects/raw/main/assets/images/Info.JPG)

Looks like I have no missing values in my data, and I have the Dtypes on hand in case I run into issues later.
Before moving on, it’s worth noting that there are three features that are numerical, but categorical. They are the key, the mode (major or minor), and the time signature of the song. I’ll quickly recode these to be factor variables:

```
saved_tracks['key_factor'] = pd.factorize(saved_tracks['key'])[0]
saved_tracks['mode_factor'] = pd.factorize(saved_tracks['mode'])[0]
saved_tracks['ts_factor'] = pd.factorize(saved_tracks['time_signature'])[0]
```


## Question 3: How are my variables distributed?

Histograms are often my favorite method of univariate visualization. To make this and later analyses easier, I’ll start by separating the truly numerical variables into their own dataframe. Then, I’ll run .hist() on that dataframe to yield the following charts:

![Quantitative Histograms](https://github.com/jcieslewicz/stat386-projects/raw/main/assets/images/quant_hist.png)

A few key takeaways:
* Popularity: it looks like most of the songs in my library are not very popular generally, which makes sense when I think about the genres I most listen to. However, it could also be that many of my songs are just older and thus less popular. We’ll dig deeper into this later.
* It seems like most of my songs are near the middle of the spectrum in danceability and tempo, but they’re all over the place in energy and valence (happiness).
* Based on these metrics, Spotify thinks that most of my songs are acoustic, but most are not instrumental or live or contain spoken (non-sung) words. I think those are all fair assessments of my music.
* Most of my songs are on the quieter side (lower absolute value of decibals)

As you can see, exploratory steps like this can yield a lot of insights from a few lines of code. Just for curiosity, I also generate histograms on the factorized variables:

![Factor Histograms](https://github.com/jcieslewicz/stat386-projects/raw/main/assets/images/factor_hist.png)

A few fun facts from these charts for music nerds:
* The most common key signature in my library is F Major
* I have more than twice as many major songs and minor songs
* My most common time signature was 4/4, which corresponds to the factorized value of 0

Simple visualizations like this can lead us to more questions, some of which have simple answers and others of which will involve more detailed analyses. Since we’re sticking to an EDA today, I’ll investigate two simple questions.

## Question 4: How are these different audio features related to one another?

As I think about the features we discussed above, it would make sense that some of them are tied together or even come in groups. A simple EDA tool to investigate these relationships is a correlation matrix. As a brief review, if two variables’ correlation coefficients are closer to 1, they have a strong, positive, linear relationship, and the reverse is true as you get closer to -1. I generate a simple, visualized correlation matrix like this:

```
corr_matrix = interesting_audio_features.corr()

palette = sns.diverging_palette(20, 220, n=256)

ax = plt.axes()
sns.heatmap(corr_matrix, cmap = palette, annot=True, fmt = '.2f', ax = ax)
ax.set_title('R^2 Coefficient Among Audio Features in Joseph\'s Spotify Library \n')
plt.show()
```

![Correlation Matrix](https://github.com/jcieslewicz/stat386-projects/raw/main/assets/images/corr_matrix.png)

Honestly, this correlation matrix doesn’t yield as many strong correlations as I would expect, which would be a good sign for conducting more complex analyses. However, there are a few relationships that stand out:
* Valence, Danceability, Energy, and Loudness all seem to have relatively strong, positive linear relationships with each other. This makes sense: a loud, happy, and high-energy song would be easier to dance to, etc.
* Acousticness has fairly strong negative relationships with energy, valence, and loudness, which again makes sense

While these relationships might seem to be intuitive, they could provide us with powerful initial insights for investigating multicollinearity or attempting a component reduction.

## Question 5: How does a song’s recency affect its popularity?

I’ve always known that my music tastes weren’t the trendiest, but when I saw an average popularity rating of 24 out of 100, I decided to investigate. It’s possible that, since I’ve been building this library for almost 8 years, the songs I initially added have become less popular over time. It’s also possible that my tastes have changed over time to become more or less mainstream. 

To begin to investigate these hypotheses, I’ll take advantage of the leftover index variable in our dataset (you could easily add one if it weren’t there already). Since the songs came from my API pull in the reverse order in which they were added to my library, I can use the reverse of this column to represent the rough “recency” of a song. (It isn’t a perfect metric, but sometimes you have to be creative). I calculate the correlation between recency and popularity and chart a scatterplot with a loess line:

![Popularity Over Time](https://github.com/jcieslewicz/stat386-projects/raw/main/assets/images/popularity.png)

A correlation of -.36 implies a weak relationship between recency and popularity: the more recent, the more popular. The chart shows that the earliest songs I added to my library have an average popularity of under 20/100, while my most recent additions average around 40/100. This seems to confirm some of my suspicions, but a simple EDA it doesn’t answer my questions specifically. It could be that my older songs were less unpopular before, or it could be that my taste in music has become (OK, only slightly) more mainstream as time as gone on.

## Conclusion

This post is not intended to be an exhaustive guide to EDA techniques, in part because your EDA process will change for each analysis you conduct. It will be guided by questions like:
* What is my dataset, and what’s the purpose of the analysis?
* How familiar am I with this data?
* What kinds of analysis tools do I hypothesize will be most relevant/useful?

EDA is the gateway to one of the greatest joys of data science: discovering meaningful truths from the messy data of reality. I hope that joining me on this brief journey has piqued your curiosity for exploring datasets that are relevant to your life.
